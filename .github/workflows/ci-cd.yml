name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    services:
      # Use MySQL service container for integration tests if needed
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: password
          MYSQL_DATABASE: test_db
        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping" --health-interval=10s --health-timeout=5s --health-retries=3
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r t1_cs/requirements.txt
          pip install pytest pytest-cov
      
      - name: Run unit tests
        run: |
          pytest t1_cs/tests/test_models.py t1_cs/tests/test_repositories.py t1_cs/tests/test_services.py --cov=t1_cs/app --cov-report=xml
      
      - name: Run database tests
        run: |
          pytest t1_cs/tests/test_database.py --cov=t1_cs/app --cov-append --cov-report=xml
      
      - name: Verify coverage report
        run: |
          if [ -f "coverage.xml" ]; then
            echo "Coverage report found at $(pwd)/coverage.xml"
          else
            echo "Warning: coverage.xml not found in expected location"
            find . -name "coverage.xml" -type f
          fi
      
      - name: Upload test coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: ./coverage.xml
          if-no-files-found: warn
      
      - name: Build Docker image
        run: |
          docker build -t fastapi-app:${{ github.sha }} .
      
      - name: Test Docker image
        run: |
          docker run --name test-container -d -p 8000:8000 fastapi-app:${{ github.sha }}
          sleep 5
          if ! curl -s http://localhost:8000/health; then
            echo "Health check failed"
            docker logs test-container
            docker stop test-container
            docker rm test-container
            exit 1
          fi
          docker stop test-container
          docker rm test-container

  deploy:
    name: Deploy to AWS
    needs: build-and-test
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Check if AWS credentials are valid
      - name: Check AWS credentials
        id: aws-cred-check
        continue-on-error: true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: us-east-1
        run: |
          echo "::warning::Checking AWS credentials..."
          if aws sts get-caller-identity &>/dev/null; then
            echo "AWS credentials are valid"
            echo "aws_creds_valid=true" >> $GITHUB_OUTPUT
          else
            echo "::error::AWS credentials are invalid or expired. For temporary credentials (Access Key ID starting with 'ASIA'), you need to provide AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN."
            echo "aws_creds_valid=false" >> $GITHUB_OUTPUT
          fi
      
      # Set AWS credentials as environment variables if they're valid
      - name: Set AWS credentials as environment variables
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_SESSION_TOKEN=${{ secrets.AWS_SESSION_TOKEN }}" >> $GITHUB_ENV
          echo "AWS_REGION=us-east-1" >> $GITHUB_ENV
          echo "AWS credentials set as environment variables"
      
      # Setup Terraform only if AWS credentials are valid
      - name: Setup Terraform
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.0
      
      # Initialize Terraform only if AWS credentials are valid
      - name: Terraform Init
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Use local backend instead of S3 since the bucket doesn't exist
          terraform init -backend=false
      
      # Create S3 bucket for Terraform state if it doesn't exist
      - name: Create S3 bucket for Terraform state
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          # Create a valid S3 bucket name (must be lowercase, no underscores, etc.)
          # Use a hash of the repository name to ensure uniqueness and valid characters
          REPO_HASH=$(echo "${{ github.repository }}" | md5sum | cut -c1-8)
          BUCKET_NAME="tf-state-$REPO_HASH"
          echo "Using S3 bucket: $BUCKET_NAME"
          
          # Check if bucket exists
          if aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
            echo "S3 bucket already exists"
          else
            echo "Creating S3 bucket: $BUCKET_NAME"
            # Create bucket in us-east-1
            aws s3api create-bucket --bucket $BUCKET_NAME --region us-east-1
            
            # Enable versioning
            aws s3api put-bucket-versioning --bucket $BUCKET_NAME --versioning-configuration Status=Enabled
            
            # Wait for bucket to be fully created
            echo "Waiting for bucket to be available..."
            sleep 10
          fi
          
          # Store bucket name for later use
          echo "TF_BUCKET_NAME=$BUCKET_NAME" >> $GITHUB_ENV
      
      # Initialize Terraform with S3 backend and reconfigure to use new resource names
      - name: Terraform Init
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Use -reconfigure to reinitialize with the new fixed resource names
          terraform init -reconfigure \
            -backend-config="bucket=${{ env.TF_BUCKET_NAME }}" \
            -backend-config="key=terraform.tfstate" \
            -backend-config="region=us-east-1"
      
      # Validate Terraform only if AWS credentials are valid
      - name: Terraform Validate
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: terraform validate
      
      # Plan Terraform only if AWS credentials are valid
      - name: Terraform Plan
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: terraform plan -var-file=terraform.tfvars
        env:
          TF_VAR_db_username: ${{ secrets.DB_USERNAME }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
          TF_VAR_environment: "prod"
      
      # Apply Terraform only if AWS credentials are valid
      - name: Terraform Apply
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true' && github.ref == 'refs/heads/main' && github.event_name == 'push'
        working-directory: ./terraform
        timeout-minutes: 15
        run: |
          # Add timeout to ensure the step doesn't run indefinitely
          terraform apply -auto-approve -var-file=terraform.tfvars
        env:
          TF_VAR_db_username: ${{ secrets.DB_USERNAME }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
          TF_VAR_environment: "prod"
      
      # Get API Gateway URL only if AWS credentials are valid
      - name: Get API Gateway URL
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Extract only the valid URL part from terraform output (stopping at ::debug:: if present)
          API_URL=$(terraform output -raw api_gateway_url | grep -o 'https://[^:[:space:]]*\(/[^:[:space:]]*\)*' | head -n 1)
          # Verify we have a valid URL
          if [[ $API_URL =~ ^https:// ]]; then
            echo "Successfully extracted API Gateway URL: $API_URL"
            echo "API_URL=$API_URL" >> $GITHUB_ENV
          else
            echo "Failed to extract a valid API Gateway URL"
            echo "Raw output was:"
            terraform output -raw api_gateway_url
            exit 1
          fi
      
      # Wait for deployment only if AWS credentials are valid
      - name: Wait for deployment to complete
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          echo "Waiting for Lambda function to be fully deployed..."
          sleep 30
      
      # Initialize the database after deployment
      - name: Initialize database
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        continue-on-error: true
        run: |
          echo "Initializing database schema and populating initial data..."
          INIT_RESPONSE=$(curl -s -X POST "${{ env.API_URL }}/admin/init-db")
          echo "Database initialization response: $INIT_RESPONSE"
          
          # Wait for database initialization to complete
          echo "Waiting for database initialization to complete..."
          sleep 10
      
      # Test deployed API only if AWS credentials are valid
      - name: Test deployed API
        id: api-test
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        continue-on-error: true  # Continue workflow even if API test fails
        run: |
          echo "Testing API at ${{ env.API_URL }}"
          # Use the clean URL variable and add proper error handling
          RESPONSE=$(curl -s "${{ env.API_URL }}/health")
          echo "$RESPONSE"
          
          # Store the response for later steps
          echo "API_RESPONSE<<EOF" >> $GITHUB_ENV
          echo "$RESPONSE" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          
          # Improved error detection - check for common error patterns and specific error messages
          if [[ "$RESPONSE" == *"Not Found"* ]] || \
             [[ "$RESPONSE" == *"error"* ]] || \
             [[ "$RESPONSE" == *"Error"* ]] || \
             [[ "$RESPONSE" == *"Internal Server Error"* ]] || \
             [[ -z "$RESPONSE" ]]; then
            echo "API health check failed - received error response"
            echo "api_test_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Also check for JSON error responses
          if [[ "$RESPONSE" == *"\"message\""* && "$RESPONSE" == *"\"Internal Server Error\""* ]]; then
            echo "API health check failed - received Internal Server Error"
            echo "api_test_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "API health check successful"
          echo "api_test_success=true" >> $GITHUB_OUTPUT
          
          # Also test the database connection
          echo "Testing database connection via db-status endpoint..."
          DB_STATUS_RESPONSE=$(curl -s "${{ env.API_URL }}/db-status")
          echo "Database status response: $DB_STATUS_RESPONSE"
      
      # Check Lambda function logs to diagnose issues
      - name: Check Lambda function logs
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true' && steps.api-test.outputs.api_test_success != 'true'
        working-directory: ./terraform
        run: |
          # Extract Lambda function name from Terraform output
          LAMBDA_FUNCTION_NAME=$(terraform output -raw lambda_function_name)
          LAMBDA_LOG_GROUP="/aws/lambda/$LAMBDA_FUNCTION_NAME"
          
          echo "Checking logs for Lambda function: $LAMBDA_FUNCTION_NAME"
          echo "Log group: $LAMBDA_LOG_GROUP"
          
          # Get the most recent log streams
          echo "Retrieving recent log streams..."
          LOG_STREAMS=$(aws logs describe-log-streams \
            --log-group-name "$LAMBDA_LOG_GROUP" \
            --order-by LastEventTime \
            --descending \
            --limit 3 \
            --query "logStreams[*].logStreamName" \
            --output text)
          
          if [ -z "$LOG_STREAMS" ]; then
            echo "::warning::No log streams found for Lambda function"
          else
            # For each log stream, get the most recent events
            for STREAM in $LOG_STREAMS; do
              echo "=== Log stream: $STREAM ==="
              aws logs get-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-name "$STREAM" \
                --limit 50 \
                --query "events[*].message" \
                --output text
              
              echo ""
            done
            
            # Look specifically for database connection errors
            echo "=== Searching for database connection errors ==="
            for STREAM in $LOG_STREAMS; do
              aws logs filter-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-names "$STREAM" \
                --filter-pattern "Database connection failed" \
                --query "events[*].message" \
                --output text
            done
            
            # Look specifically for error messages
            echo "=== Searching for error messages ==="
            for STREAM in $LOG_STREAMS; do
              aws logs filter-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-names "$STREAM" \
                --filter-pattern "ERROR" \
                --query "events[*].message" \
                --output text
            done
            
            # Check Lambda environment variables (especially database connection params)
            echo "=== Checking Lambda environment variables ==="
            ENV_VARS=$(aws lambda get-function-configuration \
              --function-name "$LAMBDA_FUNCTION_NAME" \
              --query "Environment.Variables" \
              --output json)
            
            # Print environment variables without sensitive information
            echo "$ENV_VARS" | jq 'with_entries(if .key | test("DB_PASSWORD") then .value = "***" else . end)'
            
            # Check if DB_HOST is set correctly
            DB_HOST=$(echo "$ENV_VARS" | jq -r '.DB_HOST // "not set"')
            echo "DB_HOST: $DB_HOST"
            
            # Verify RDS instance exists and is available
            echo "=== Checking RDS instance status ==="
            if [[ "$DB_HOST" != "not set" && "$DB_HOST" != "localhost" ]]; then
              # Extract the RDS identifier from the hostname
              RDS_IDENTIFIER=$(echo "$DB_HOST" | cut -d'.' -f1)
              
              if [[ -n "$RDS_IDENTIFIER" ]]; then
                echo "Attempting to check RDS instance: $RDS_IDENTIFIER"
                aws rds describe-db-instances \
                  --db-instance-identifier "$RDS_IDENTIFIER" \
                  --query "DBInstances[0].{Status:DBInstanceStatus, Engine:Engine, Endpoint:Endpoint.Address}" \
                  --output json || echo "Could not find RDS instance with identifier: $RDS_IDENTIFIER"
              else
                echo "Could not extract RDS identifier from DB_HOST: $DB_HOST"
              fi
            else
              echo "DB_HOST not properly configured: $DB_HOST"
            fi
          fi
      
      # Display warning if AWS credentials are invalid
      - name: AWS credentials warning
        if: steps.aws-cred-check.outputs.aws_creds_valid != 'true'
        run: |
          echo "::warning::Skipping deployment steps due to invalid AWS credentials. Please update the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY secrets."
      
      - name: Check for Slack webhook
        id: check-slack-webhook
        if: always()
        run: |
          if [[ -n "${{ secrets.SLACK_WEBHOOK }}" ]]; then
            echo "has_slack_webhook=true" >> $GITHUB_OUTPUT
          else
            echo "::warning::SLACK_WEBHOOK secret is not set. Skipping Slack notification."
            echo "has_slack_webhook=false" >> $GITHUB_OUTPUT
          fi

      - name: Send deployment notification
        if: always() && steps.check-slack-webhook.outputs.has_slack_webhook == 'true'
        uses: rtCamp/action-slack-notify@v2.2.0
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          SLACK_CHANNEL: deployments
          SLACK_COLOR: ${{ job.status }}
          SLACK_TITLE: Deployment ${{ job.status }}
          # Use a conditional message based on whether API_URL is set
          SLACK_MESSAGE: ${{ env.API_URL != '' && format('API deployed to {0}', env.API_URL) || 'Deployment completed but API URL not available' }}