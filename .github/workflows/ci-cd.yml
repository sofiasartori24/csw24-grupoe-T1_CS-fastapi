name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    
    services:
      # Use MySQL service container for integration tests if needed
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: password
          MYSQL_DATABASE: test_db
        ports:
          - 3306:3306
        options: --health-cmd="mysqladmin ping" --health-interval=10s --health-timeout=5s --health-retries=3
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r t1_cs/requirements.txt
          pip install pytest pytest-cov
      
      - name: Run unit tests
        run: |
          pytest t1_cs/tests/test_models.py t1_cs/tests/test_repositories.py t1_cs/tests/test_services.py --cov=t1_cs/app --cov-report=xml
      
      - name: Run database tests
        run: |
          pytest t1_cs/tests/test_database.py --cov=t1_cs/app --cov-append --cov-report=xml
      
      - name: Verify coverage report
        run: |
          if [ -f "coverage.xml" ]; then
            echo "Coverage report found at $(pwd)/coverage.xml"
          else
            echo "Warning: coverage.xml not found in expected location"
            find . -name "coverage.xml" -type f
          fi
      
      - name: Upload test coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: ./coverage.xml
          if-no-files-found: warn
      
      - name: Build Docker image
        run: |
          docker build -t fastapi-app:${{ github.sha }} .
      
      - name: Test Docker image
        run: |
          docker run --name test-container -d -p 8000:8000 fastapi-app:${{ github.sha }}
          sleep 5
          if ! curl -s http://localhost:8000/health; then
            echo "Health check failed"
            docker logs test-container
            docker stop test-container
            docker rm test-container
            exit 1
          fi
          docker stop test-container
          docker rm test-container

  deploy:
    name: Deploy to AWS
    needs: build-and-test
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Check if AWS credentials are valid
      - name: Check AWS credentials
        id: aws-cred-check
        continue-on-error: true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: us-east-1
        run: |
          echo "::warning::Checking AWS credentials..."
          if aws sts get-caller-identity &>/dev/null; then
            echo "AWS credentials are valid"
            echo "aws_creds_valid=true" >> $GITHUB_OUTPUT
          else
            echo "::error::AWS credentials are invalid or expired. For temporary credentials (Access Key ID starting with 'ASIA'), you need to provide AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN."
            echo "aws_creds_valid=false" >> $GITHUB_OUTPUT
          fi
      
      # Set AWS credentials as environment variables if they're valid
      - name: Set AWS credentials as environment variables
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_SESSION_TOKEN=${{ secrets.AWS_SESSION_TOKEN }}" >> $GITHUB_ENV
          echo "AWS_REGION=us-east-1" >> $GITHUB_ENV
          echo "AWS credentials set as environment variables"
      
      # Setup Terraform only if AWS credentials are valid
      - name: Setup Terraform
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.0
      
      # Initialize Terraform only if AWS credentials are valid
      - name: Terraform Init
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Use local backend instead of S3 since the bucket doesn't exist
          terraform init -backend=false
      
      # Create S3 bucket for Terraform state if it doesn't exist
      - name: Create S3 bucket for Terraform state
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          # Create a valid S3 bucket name (must be lowercase, no underscores, etc.)
          # Use a hash of the repository name to ensure uniqueness and valid characters
          REPO_HASH=$(echo "${{ github.repository }}" | md5sum | cut -c1-8)
          BUCKET_NAME="tf-state-$REPO_HASH"
          echo "Using S3 bucket: $BUCKET_NAME"
          
          # Check if bucket exists
          if aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
            echo "S3 bucket already exists"
          else
            echo "Creating S3 bucket: $BUCKET_NAME"
            # Create bucket in us-east-1
            aws s3api create-bucket --bucket $BUCKET_NAME --region us-east-1
            
            # Enable versioning
            aws s3api put-bucket-versioning --bucket $BUCKET_NAME --versioning-configuration Status=Enabled
            
            # Wait for bucket to be fully created
            echo "Waiting for bucket to be available..."
            sleep 10
          fi
          
          # Store bucket name for later use
          echo "TF_BUCKET_NAME=$BUCKET_NAME" >> $GITHUB_ENV
      
      # Initialize Terraform with S3 backend and reconfigure to use new resource names
      - name: Terraform Init
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Use -reconfigure to reinitialize with the new fixed resource names
          terraform init -reconfigure \
            -backend-config="bucket=${{ env.TF_BUCKET_NAME }}" \
            -backend-config="key=terraform.tfstate" \
            -backend-config="region=us-east-1"
      
      # Validate Terraform only if AWS credentials are valid
      - name: Terraform Validate
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: terraform validate
      
      # Plan Terraform only if AWS credentials are valid
      - name: Terraform Plan
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: terraform plan -var-file=terraform.tfvars
        env:
          TF_VAR_db_username: ${{ secrets.DB_USERNAME }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
          TF_VAR_environment: "prod"
      
      # Check if RDS instance exists before applying Terraform
      - name: Check RDS instance
        id: check-rds
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        continue-on-error: true
        run: |
          # Check if the RDS instance exists
          RDS_IDENTIFIER="resources-management-db"
          echo "Checking if RDS instance '$RDS_IDENTIFIER' exists..."
          
          if aws rds describe-db-instances --db-instance-identifier "$RDS_IDENTIFIER" &>/dev/null; then
            echo "RDS instance '$RDS_IDENTIFIER' exists"
            echo "rds_exists=true" >> $GITHUB_OUTPUT
            
            # Get RDS endpoint
            RDS_ENDPOINT=$(aws rds describe-db-instances \
              --db-instance-identifier "$RDS_IDENTIFIER" \
              --query "DBInstances[0].Endpoint.Address" \
              --output text)
            
            echo "RDS endpoint: $RDS_ENDPOINT"
            echo "rds_endpoint=$RDS_ENDPOINT" >> $GITHUB_OUTPUT
          else
            echo "::warning::RDS instance '$RDS_IDENTIFIER' does not exist"
            echo "This will likely cause the Lambda function to fail with 'Internal Server Error'"
            echo "rds_exists=false" >> $GITHUB_OUTPUT
          fi
      
      # Apply Terraform only if AWS credentials are valid
      - name: Terraform Apply
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true' && github.ref == 'refs/heads/main' && github.event_name == 'push'
        working-directory: ./terraform
        timeout-minutes: 15
        run: |
          # Add timeout to ensure the step doesn't run indefinitely
          terraform apply -auto-approve -var-file=terraform.tfvars
        env:
          TF_VAR_db_username: ${{ secrets.DB_USERNAME }}
          TF_VAR_db_password: ${{ secrets.DB_PASSWORD }}
          TF_VAR_environment: "prod"
      
      # Get API Gateway URL only if AWS credentials are valid
      - name: Get API Gateway URL
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        working-directory: ./terraform
        run: |
          # Extract only the valid URL part from terraform output (stopping at ::debug:: if present)
          API_URL=$(terraform output -raw api_gateway_url | grep -o 'https://[^:[:space:]]*\(/[^:[:space:]]*\)*' | head -n 1)
          # Verify we have a valid URL
          if [[ $API_URL =~ ^https:// ]]; then
            echo "Successfully extracted API Gateway URL: $API_URL"
            echo "API_URL=$API_URL" >> $GITHUB_ENV
          else
            echo "Failed to extract a valid API Gateway URL"
            echo "Raw output was:"
            terraform output -raw api_gateway_url
            exit 1
          fi
      
      # Wait for deployment only if AWS credentials are valid
      - name: Wait for deployment to complete
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        run: |
          echo "Waiting for Lambda function to be fully deployed..."
          sleep 30
      
      # Initialize the database after deployment
      - name: Initialize database
        id: init-db
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        continue-on-error: true
        run: |
          echo "Initializing database schema and populating initial data..."
          INIT_RESPONSE=$(curl -s -X POST "${{ env.API_URL }}/admin/init-db")
          echo "Database initialization response: $INIT_RESPONSE"
          
          # Check if initialization was successful
          if [[ "$INIT_RESPONSE" == *"Database initialized successfully"* ]]; then
            echo "Database initialization successful"
            echo "db_init_success=true" >> $GITHUB_OUTPUT
          else
            echo "Database initialization failed or returned an error"
            echo "db_init_success=false" >> $GITHUB_OUTPUT
            
            # Check if the response contains an error message
            if [[ "$INIT_RESPONSE" == *"Internal Server Error"* ]]; then
              echo "::warning::Database initialization returned Internal Server Error"
              echo "This may indicate a problem with the database connection"
            fi
          fi
          
          # Wait for database initialization to complete
          echo "Waiting for database initialization to complete..."
          sleep 10
      
      # Test deployed API only if AWS credentials are valid
      - name: Test deployed API
        id: api-test
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true'
        continue-on-error: true  # Continue workflow even if API test fails
        run: |
          echo "Testing API at ${{ env.API_URL }}"
          # Use the clean URL variable and add proper error handling
          RESPONSE=$(curl -s "${{ env.API_URL }}/health")
          echo "$RESPONSE"
          
          # Store the response for later steps
          echo "API_RESPONSE<<EOF" >> $GITHUB_ENV
          echo "$RESPONSE" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          
          # Improved error detection - check for common error patterns and specific error messages
          if [[ "$RESPONSE" == *"Not Found"* ]] || \
             [[ "$RESPONSE" == *"error"* ]] || \
             [[ "$RESPONSE" == *"Error"* ]] || \
             [[ "$RESPONSE" == *"Internal Server Error"* ]] || \
             [[ -z "$RESPONSE" ]]; then
            echo "API health check failed - received error response"
            echo "api_test_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Also check for JSON error responses
          if [[ "$RESPONSE" == *"\"message\""* && "$RESPONSE" == *"\"Internal Server Error\""* ]]; then
            echo "API health check failed - received Internal Server Error"
            echo "api_test_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "API health check successful"
          echo "api_test_success=true" >> $GITHUB_OUTPUT
          
          # Also test the database connection
          echo "Testing database connection via db-status endpoint..."
          DB_STATUS_RESPONSE=$(curl -s "${{ env.API_URL }}/db-status")
          echo "Database status response: $DB_STATUS_RESPONSE"
      
      # Check Lambda function logs to diagnose issues
      - name: Check Lambda function logs
        if: steps.aws-cred-check.outputs.aws_creds_valid == 'true' && steps.api-test.outputs.api_test_success != 'true'
        working-directory: ./terraform
        run: |
          # Use a hardcoded Lambda function name from the logs
          echo "Using Lambda function name from previous logs..."
          LAMBDA_FUNCTION_NAME="FastAPIApplication-20250605005207"
          LAMBDA_LOG_GROUP="/aws/lambda/$LAMBDA_FUNCTION_NAME"
          
          echo "Checking logs for Lambda function: '$LAMBDA_FUNCTION_NAME'"
          echo "Log group: '$LAMBDA_LOG_GROUP'"
          
          # Get the most recent log streams
          echo "Retrieving recent log streams..."
          LOG_STREAMS=$(aws logs describe-log-streams \
            --log-group-name "$LAMBDA_LOG_GROUP" \
            --order-by LastEventTime \
            --descending \
            --limit 3 \
            --query "logStreams[*].logStreamName" \
            --output text)
          
          if [ -z "$LOG_STREAMS" ]; then
            echo "::warning::No log streams found for Lambda function"
          else
            # For each log stream, get the most recent events
            for STREAM in $LOG_STREAMS; do
              echo "=== Log stream: $STREAM ==="
              aws logs get-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-name "$STREAM" \
                --limit 50 \
                --query "events[*].message" \
                --output text
              
              echo ""
            done
            
            # Look specifically for database connection errors
            echo "=== Searching for database connection errors ==="
            for STREAM in $LOG_STREAMS; do
              aws logs filter-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-names "$STREAM" \
                --filter-pattern "Database connection failed" \
                --query "events[*].message" \
                --output text
            done
            
            # Look specifically for error messages
            echo "=== Searching for error messages ==="
            for STREAM in $LOG_STREAMS; do
              aws logs filter-log-events \
                --log-group-name "$LAMBDA_LOG_GROUP" \
                --log-stream-names "$STREAM" \
                --filter-pattern "ERROR" \
                --query "events[*].message" \
                --output text
            done
            
            # Check Lambda environment variables (especially database connection params)
            echo "=== Checking Lambda environment variables ==="
            ENV_VARS=$(aws lambda get-function-configuration \
              --function-name "$LAMBDA_FUNCTION_NAME" \
              --query "Environment.Variables" \
              --output json)
            
            # Print environment variables without sensitive information
            echo "$ENV_VARS" | jq 'with_entries(if .key | test("DB_PASSWORD") then .value = "***" else . end)'
            
            # Check if DB_HOST is set correctly
            DB_HOST=$(echo "$ENV_VARS" | jq -r '.DB_HOST // "not set"')
            DB_USER=$(echo "$ENV_VARS" | jq -r '.DB_USER // "not set"')
            DB_NAME=$(echo "$ENV_VARS" | jq -r '.DB_NAME // "not set"')
            
            echo "DB_HOST: $DB_HOST"
            echo "DB_USER: $DB_USER"
            echo "DB_NAME: $DB_NAME"
            
            # Check if DB_HOST matches the RDS endpoint
            if [[ "$DB_HOST" != "${{ steps.check-rds.outputs.rds_endpoint }}" && "${{ steps.check-rds.outputs.rds_endpoint }}" != "" ]]; then
              echo "::warning::DB_HOST in Lambda environment ($DB_HOST) does not match RDS endpoint (${{ steps.check-rds.outputs.rds_endpoint }})"
              echo "This may cause connection issues"
            fi
            
            # Try to connect to the RDS instance directly to verify credentials and check schema
            echo "=== Attempting to connect to RDS instance ==="
            if [[ -n "$DB_HOST" && -n "$DB_USER" && -n "$DB_NAME" ]]; then
              echo "Installing MySQL client..."
              apt-get update -qq && apt-get install -qq -y mysql-client
              
              echo "Attempting to connect to MySQL at $DB_HOST..."
              if mysql -h "$DB_HOST" -u "$DB_USER" -p"${{ secrets.DB_PASSWORD }}" -e "SELECT 1" "$DB_NAME" 2>/dev/null; then
                echo "Successfully connected to RDS instance"
                
                # Check if tables exist in the database
                echo "Checking if tables exist in the database..."
                TABLES=$(mysql -h "$DB_HOST" -u "$DB_USER" -p"${{ secrets.DB_PASSWORD }}" -e "SHOW TABLES" "$DB_NAME" 2>/dev/null)
                
                if [[ -z "$TABLES" ]]; then
                  echo "::warning::No tables found in the database. This is likely the cause of the Internal Server Error."
                  echo "The database exists but the schema hasn't been created."
                else
                  echo "Tables found in the database:"
                  echo "$TABLES"
                fi
              else
                echo "::warning::Failed to connect to RDS instance. This may indicate incorrect credentials or security group issues."
              fi
            fi
            
            # Verify RDS instance exists and is available
            echo "=== Checking RDS instance status ==="
            if [[ "$DB_HOST" != "not set" && "$DB_HOST" != "localhost" ]]; then
              # Extract the RDS identifier from the hostname
              RDS_IDENTIFIER=$(echo "$DB_HOST" | cut -d'.' -f1)
              
              if [[ -n "$RDS_IDENTIFIER" ]]; then
                echo "Attempting to check RDS instance: $RDS_IDENTIFIER"
                RDS_INFO=$(aws rds describe-db-instances \
                  --db-instance-identifier "$RDS_IDENTIFIER" \
                  --query "DBInstances[0].{Status:DBInstanceStatus, Engine:Engine, Endpoint:Endpoint.Address, VpcId:DBSubnetGroup.VpcId}" \
                  --output json 2>&1) || echo "Could not find RDS instance with identifier: $RDS_IDENTIFIER"
                
                echo "$RDS_INFO"
                
                # Check if RDS instance is in the same VPC as Lambda
                if [[ "$RDS_INFO" == *"VpcId"* ]]; then
                  RDS_VPC_ID=$(echo "$RDS_INFO" | jq -r '.VpcId // "unknown"')
                  echo "RDS VPC ID: $RDS_VPC_ID"
                  
                  # Get Lambda VPC ID
                  LAMBDA_VPC_INFO=$(aws lambda get-function-configuration \
                    --function-name "$LAMBDA_FUNCTION_NAME" \
                    --query "VpcConfig" \
                    --output json)
                  
                  echo "Lambda VPC Config: $LAMBDA_VPC_INFO"
                  
                  LAMBDA_VPC_ID=$(echo "$LAMBDA_VPC_INFO" | jq -r '.VpcId // "unknown"')
                  echo "Lambda VPC ID: $LAMBDA_VPC_ID"
                  
                  if [[ "$RDS_VPC_ID" != "$LAMBDA_VPC_ID" && "$LAMBDA_VPC_ID" != "unknown" && "$RDS_VPC_ID" != "unknown" ]]; then
                    echo "::warning::RDS instance and Lambda function are in different VPCs"
                    echo "RDS VPC: $RDS_VPC_ID, Lambda VPC: $LAMBDA_VPC_ID"
                  fi
                fi
                
                # Check security group rules
                echo "=== Checking security group rules ==="
                RDS_SG_ID=$(aws rds describe-db-instances \
                  --db-instance-identifier "$RDS_IDENTIFIER" \
                  --query "DBInstances[0].VpcSecurityGroups[0].VpcSecurityGroupId" \
                  --output text 2>/dev/null)
                
                if [[ -n "$RDS_SG_ID" ]]; then
                  echo "RDS Security Group ID: $RDS_SG_ID"
                  
                  # Check if Lambda security group can access RDS
                  LAMBDA_SG_ID=$(echo "$LAMBDA_VPC_INFO" | jq -r '.SecurityGroupIds[0] // "unknown"')
                  echo "Lambda Security Group ID: $LAMBDA_SG_ID"
                  
                  if [[ "$LAMBDA_SG_ID" != "unknown" ]]; then
                    SG_RULES=$(aws ec2 describe-security-group-rules \
                      --filter "Name=group-id,Values=$RDS_SG_ID" \
                      --query "SecurityGroupRules[?FromPort==3306]" \
                      --output json)
                    
                    echo "RDS Security Group Rules for port 3306: $SG_RULES"
                    
                    # Check if Lambda SG is allowed
                    if [[ "$SG_RULES" == *"$LAMBDA_SG_ID"* ]]; then
                      echo "Lambda security group is allowed to access RDS"
                    else
                      echo "::warning::Lambda security group may not have access to RDS"
                    fi
                  fi
                fi
              else
                echo "Could not extract RDS identifier from DB_HOST: $DB_HOST"
              fi
            else
              echo "DB_HOST not properly configured: $DB_HOST"
            fi
          fi
      
      # Display warning if AWS credentials are invalid
      - name: AWS credentials warning
        if: steps.aws-cred-check.outputs.aws_creds_valid != 'true'
        run: |
          echo "::warning::Skipping deployment steps due to invalid AWS credentials. Please update the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY secrets."
      
      - name: Check for Slack webhook
        id: check-slack-webhook
        if: always()
        run: |
          if [[ -n "${{ secrets.SLACK_WEBHOOK }}" ]]; then
            echo "has_slack_webhook=true" >> $GITHUB_OUTPUT
          else
            echo "::warning::SLACK_WEBHOOK secret is not set. Skipping Slack notification."
            echo "has_slack_webhook=false" >> $GITHUB_OUTPUT
          fi

      - name: Send deployment notification
        if: always() && steps.check-slack-webhook.outputs.has_slack_webhook == 'true'
        uses: rtCamp/action-slack-notify@v2.2.0
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          SLACK_CHANNEL: deployments
          SLACK_COLOR: ${{ job.status }}
          SLACK_TITLE: Deployment ${{ job.status }}
          # Use a conditional message based on whether API_URL is set
          SLACK_MESSAGE: ${{ env.API_URL != '' && format('API deployed to {0}', env.API_URL) || 'Deployment completed but API URL not available' }}